\chapter{}
\section{Introduction}
This dissertation is a description of transcription factor binding that allows for prediction of the behavior of the Dorsal Ventral patterning gene regulatory network of Drosophila early development.  Although Drosophila, the fruit fly, is much simpler than human, its molecular biology contains many similar to almost identical mechanisms for controlling genes, and hence is in the premiere league of modeling systems for understanding how human genes are molecularly controlled.  

Genes, in a broad sense, are the particles that are passed on from parents to progeny that contain the information about the characteristics of the parent.  The characteristics of the parents are their 'traits', like eye color, susceptibility to diabetes II, or fecundity (a proxy for 'fitness')).  Hence knowledge of one's genes, or a population of people's genes, a gene pool, allows one to make predictions about what traits will exist in future generations.

The 'traits' of interest in this dissertation are not at the level of the adult, or even at the level of a recognizable animal.  They are at the cellular level, where 'development' builds an adult by 'developing' different cell types that are arranged together to form an adult body plan.  The initial steps of turning a totipotent cell (the zygote) into a ball of thousands of cells, the embryo, where each cell has its very own genome that becomes fated to be the brain, the heart, etc.. of the fly through gene regulation.

The aspect of gene regulation that I focus on is at the level of transcription.  The first step in the 'central dogma', where DNA is copied to an RNA sequence.  It is the control of this that we will consider 'regulation', where control is in the sense of how many RNA 'transcipts' should be produced.
  
The reason we focus on the dogma and on development is because 'development' produces in tandem with production of RNA a set of controlled experiments, which are currently at the cutting edge of experimental set ups in the lab.   For example, a cutting edge experiment is in vitro reconstitution experiments which allow for the production of RNA by putting the 50 to 100 different particles necessary together in an in vitro environment to replicate the complicated mesoscale process of regulation of transcription.  This is not simply throwing bacterial polymerase in with DNA, such as performed with polymerase chain reaction (PCR), it's placing the nucleosomes (mesoscale) and all the basal transcription factors (fat nanoparticles) and the many mediator particles and the the distal enhancers and transcription factors and adaptors all together to see what minimally gets the process of transcription to work. 

The fly embryo produces a set of cells that are all under the same conditions, just as a technician would set up a pitri dish full of cells under similar conditions.  Each of these cells is reliably producing transcripts at a particular point in time in development, where the time reproducibility is a function of the temperature.  The dogma allows for us to observe the emitted particles from a cell or from the genome, the transcripts or the proteins they eventually produce.  It is these particles that allow for deciphering the mechanism of control of genes.   

  
Maternally controlled molecules, controlled in the sense of being positioned at different locations of the embryonic shell, diffuse or are actively transported to the individual cells of the embryo to control specific genes in the genome that reside in each of the cells.  In early fly development the cells of the embryo, each with their own genome, form a monolayer around a spherical yoke, like corn on the cob, and hence the maternal chamber has access to all the cells of the embryo in early development.  

By observing both the input maternally laid particles and the behavior of the emitted particles, the mRNA and the proteins they produce, we can decipher what is occurring at the gene regulatory level.  The obvious inference is that the input maternal molecules must somehow pass a message to the gene that is being controlled.  The mechanism that I study for gene regulation is where the input molecule 'binds' to a location specific segment of DNA, such as the DNA sequence GGAAAATCC, and thereby passing a message to the flanking sequence of the DNA 'binding site'.

Chemically, the message may begin by the bound protein adding a chemical motif to a protein that already was bound or wrapped up in the DNA like a 'histone'.  This additional chemical motif may set a motion a cascade of further steps that ultimately lead to a clear modification of transcription levels.
  
  The easiest message to observe is 'turn on' or 'turn off', which is seen through the dogma, through transcription, because we can easily observe proteins and RNA through common lab techniques. But broadly, regulation of genes by the 'binding' process means controlling the inheritable flanking sequences of the docking site \footnote{The controlled flanking sequence may not be a dogmatic 'gene' that encodes for a protein, it could be anything that is useful for the organism fitness, and is therefore selected by evolution.  In this sense, the binding site itself is a gene if it is under selection.  Hence the molecular phenotype 'to bind' is expressed by the binding site sequence, the genotype.  }.
  
  Clearly, how the maternal message, leads to a molecule binding to location specific position of the genome, i.e. it finds the gene of interest, seems to be a complicated process.  For example, random binding or sampling sites in the genome, in the time allocated during development, would not allow the messenger sufficient time to find the target, even with the mass action of multiple messengers.  
  
  To help understand how the binding process works, a central problem is understanding how the protein recognizes a specific location in the genome.  By better understanding of how proteins or the messengers recognize specific binding sites within the genome, problems such as the diffusion maternal molecules or the active transport of the messenger to a specific location in the genome may be better understood.  In a broader sense, any cellular message that requires the modulation of transcription levels, will be better elucidated by a well formulated understanding of the protein-DNA interactions, the recognition problem.
   
   A central assumption in this work is that the recognition is encoded in the DNA.  Hence the binding sites are more than just a surface upon which the protein deposits.  Just as vapor deposition can be controlled by placing specific types of high affinity surfaces mixed with low affinity surfaces, so too, one could imagine the protein binding to regions of the genome solely due to high affinity surfaces that consist of material that is not DNA, such as binding to a histone or histone tails (histones are proteins always present that occupy a large fraction of the genome), or binding to other proteins that are already bound to the genome.  I am solely interested in protein-DNA binding, and hence the differential affinity of the surface is only of interest for regions of the genome that have the DNA exposed and specifically protein-DNA binding that are under selection (i.e. it's functional DNA).  
   
   The natural mathematical physic's framework to discuss this problem, is through deposition of particles to a one dimensional lattice, the genome.  Hence, I will introduce the mathematical physics necessary for performing calculations of binding energies and occupation numbers of lattice sites.  This machinery is very general, and is not specific to the recognition problem.  

Once I have presented how 'binding' is represented I will introduce k-mers and the recognition problem, where we will account for the specific binding to ordered arrays of bases, sequences of DNA.  This leads to applications in bioinformatic sequence alignment, where known binding energies to specific sequence of DNA can be used as a computational search for potential discovery of unannotated binding sites (i.e. not in a database) within a sequenced genome, and the inverse problem where known sequences of binding sites can be used to infer the binding energy.  In particular, the first chapter of this dissertation will introduce a 'mixture model', where a mix of binding sites for the same factor, Dorsal, are used for prediction of unknown sites.  This is also used to explore the possibility of epistasis and physical cooperativity between Dorsal and cooccurring Twist binding sites.  This interaction is encoded in Dorsal binding sites, where the cooperatively encoded binding sites form one component of the 'mixture model'.  Given the foundation of protein-DNA recognition.

Chapter 2 considers further the prediction of unknown sites for the trio Dorsal, Twist, Snail; three of the dominant 'morphogens' or transcription factors in Dorsal Ventral patterning in early development of Drosophila.  Here I explore the possibility that recognition is a function not only of the preferred k-mer sequence for a given factor, but also depend on different locations of the embryo (such as the neuroectoderm, or mesoderm) which contain different concentrations of these factors and therefore their recognition to specific sequences of DNA in those regions of the embryo is modulated, which is manifested by the differential expression of their target genes.  Here I also explore the prediction of unknown sites as a function of the spacer between co-occurring k-mer sites.  This is important in Drosophila, where it has been extensively documented as the primary mechanism of 'repression' utilized by Snail, a so-called short range repressor factor that turns genes off that would otherwise be activated by the activator transcription factor Dorsal that is in high concentrations in the ventral location of the embryo.  Furthermore, this function that predicts binding sites as a function of the spacer also is explored in terms of the cooperativity between Dorsal and Twist factors, both known activators, that are known to act synergistically when their k-mer binding sites co-occur with a specific 'window' of spacer values (e.g. the sites must be about 2 to 30 base-pairs from each other).   

The DV network of enhancer's occupancy for these factors is calculated as a subproblem in the optimization of a gene expression model for the DV network of genes that is location specific within the embryo (thereby accounting for location specific concentrations).  The input to the model is a two-dimensional profile of the concentration of the transcription factors along the Dorsal-Ventral position axis of the fly embryo, along with the corresponding profiles for the target genes whose mRNA expression is modulated due to regulation by the factor binding.  The binding is accounted for by additionally inputting the cis-Regulatory Modules, or flanking sequence of DNA near the target genes where the factors are known to bind.  The model contains unknown constants that are fit using root mean square error for the objective function F, where  $F=\sum_i \sum_j (M_{ij}-O_{ij})^2$ , here M is the model output for a given evaluation of the objective function (i.e. for a given values of the parameters) and the observed data O, where i runs over the positions of the Dorsal Ventral axis, and each j is a particular gene in the network.   In addition, the objective function has an option of running a multi-objective that will add an additional objective to fit the occupancies of the factors to Chip-Seq or Chip-Chip data for the trans-factors, hence in the multiobjective case one has $F=\sum_i \sum_j(M_{ij}-O_{ij})^2 + \sum_k \sum_l (<N_{kl}>-I_{kl} )^2$, where the new term calculates the model occupancy $<N_{kl}>$ for the genomic segment k for transcription factor l, which was observed with intensity $I_{kl}$.  

\subsection{Phase space, a real vector space }
Classically one can calculate the statistical properties of many body systems, such as a gas with Avogodro's number of particles, by transforming Newton's second order differential equation for each particle to two first order differential equations for each particle, and then, upon solving the equations of motion, one can calculate time averages of quantities of interest.  Another approach is through Hamilton's principle, which is a principle of parsimony, dictating that motion follows a path of 'least action' (the shortest path, where 'shortest' has a special formulation).  This approach also consists of two first order differential equations for each positional degree of freedom, and consist of constructing the 'Hamiltonian' of the system, which is effectively the total energy of the system (at least for systems that we are interested in).  For example, for an isolated one dimensional system (such as a stretched out genome) of M particles (or M genomic units) one has:
  \begin{equation}\label{hamiltonian}
    H= \sum_i^M \frac{P_i^2}{2*m_i} + U(X_1, X_2,\dotsc ,X_M)
  \end{equation}
  H is the Hamiltonian, i indicates the particle label, and P is the momentum\footnote{\input{CK}}, and U is the potential energy of the system due to the interactions of the particles, which is a function of each particle's location X.  
  
  The 2M random variable joint distribution for the isolated system describes the occupancy of one point in phase space at any particular instant ($X_1=x_1,X_2=x_2\dotsc X_M=x_M, P_1=p_1,P_2=p2\dotsc P_M= p_M,t=0$).  Given some time t has elapsed, the distribution will be found to occupy some other point, ($X_1=x_1(t),X_2=x_2(t)\dotsc X_M=x_M(t), P_1=p_1(t),P_2=p2(t)\dotsc P_M=p_M(t)$), this is a delta distribution for each particle's position and momentum\cite{vankampen}.  Hence this is a real vector space in $R^{2M}$.
     This construction is an example of the microcanonical ensemble.  By loosening the isolation constraint (i.e. allowing energy of the system to vary), we have the canonical ensemble which has nonzero variance for many of the random variables.

 If we label our phase space points with an index i, then the occupation of point i in phase space, $n_i$. could be normalized by the occupation of all states (points in phase space), we would find:
    \begin{equation}\label{}
   \frac{ n_i}{n} =\frac{ \exp\frac{-H_i}{kT} }{ Q }
  \end{equation}
  Here $H_i$, is the Hamiltonian evaluated at the phase space point i (just plug in the corresponding positions and momentum of each particle for that state into the Hamiltonian).  The number of phase space points is determined by how well we can resolve our subspaces for each particle.  For example, the configuration space, the vector space over the position coordinates X, would be meshed no finer that are ability to resolve different distances.  Here, Q is the partition function, which can be shown by the maximum entropy principle to equal:
  \begin{equation}\label{}
     Q= \sum_i \exp{-\frac{H_i}{kT}} = \sum_i \exp{-\frac{ \sum_j^{2M} \frac{P_j(i)^2}{2*m_j} + U(X_1(i), X_2(i)\dotsc X_M(i))}{kT} }
  \end{equation}

By using the size of a unit of the genomic biopolymer as the unit of our length scale for each particle's position subspace, we can mesh out phase space's 'configuration space' such that each base at each position along the polymer chain occupies a given location (mesh point) in 'configuration space'.  The method to mesh out momentum space is irrelevant, since we are about to 'project out' or 'marginalize out' that portion of phase space.  

By asserting that the biopolymer is stretched out, and its length and hence number of 'unit's is fixed, we can reduce configuration space to contain M mesh points (one for each unit of the polymer).  This is a 'one dimensional' lattice, where the dimensionality is now in reference to the fact that each unit of the polymer lies along a linear array, like a thin spaghetti noodle that was still solid and was notched for each unit of the polymer.

We are interested in 'binding', where a distinct specie like a type of transcription factor 'binds' to the lattice.  This requires more complexity, as we now must introduce more particles than the original M units of the polymer.  Before we introduce more particles, we will first get rid of the momenta.  We define a reference system with no interactions (U=0), which has a corresponding partition function $Q_o$, then we would expect that for small interactions (U is small) the velocity distribution (Maxwell Boltzmann distribution), would effectively remain invariant.  Hence we have an effective partition function, q, defined as:
\begin{equation}\label{idealgasq}
  q = \frac{Q}{Q_o} \approx \sum_i \exp{-\frac{U(X_1(i), X_2(i)\dotsc X_n(i))}{kT} }
  \end{equation}
classically this is called the configuration integral.  This is effectively a 'projection' or marginalization over the momentum coordinates.